{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Proses Training untuk buat Model"
      ],
      "metadata": {
        "id": "H6ZkTkIfxwfK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Sastrawi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSutS0H5vfXH",
        "outputId": "3cce963c-cbd8-4238-e87a-78da47c82153"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Sastrawi\n",
            "  Downloading Sastrawi-1.0.1-py2.py3-none-any.whl.metadata (909 bytes)\n",
            "Downloading Sastrawi-1.0.1-py2.py3-none-any.whl (209 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/209.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/209.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bRDtxvWBvL1h"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import joblib\n",
        "import numpy as np\n",
        "import re\n",
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Indonesian Stemmer\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "\n",
        "# Function to preprocess text: lowercase, remove punctuation, and lemmatize\n",
        "def preprocess_text(text):\n",
        "    # Lowercase the text\n",
        "    text = text.lower()\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "    # Lemmatize each word\n",
        "    words = text.split()\n",
        "    lemmatized_words = [stemmer.stem(word) for word in words]\n",
        "    # Join the words back into a single string\n",
        "    return ' '.join(lemmatized_words)"
      ],
      "metadata": {
        "id": "L8eSy62Dva6m"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/Muhammad-Ikhwan-Fathulloh/Artificial-Intelligence-Super-Class-Batch-1/refs/heads/main/Text_Query/data.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CxzZyfrvs96",
        "outputId": "7e26b3ad-af28-4028-f162-9502971c8688"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-24 15:23:37--  https://raw.githubusercontent.com/Muhammad-Ikhwan-Fathulloh/Artificial-Intelligence-Super-Class-Batch-1/refs/heads/main/Text_Query/data.json\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4985 (4.9K) [text/plain]\n",
            "Saving to: ‘data.json’\n",
            "\n",
            "\rdata.json             0%[                    ]       0  --.-KB/s               \rdata.json           100%[===================>]   4.87K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-03-24 15:23:37 (60.3 MB/s) - ‘data.json’ saved [4985/4985]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the corpus\n",
        "with open(\"data.json\", \"r\") as file:\n",
        "    corpus = json.load(file)[\"qa_corpus\"]"
      ],
      "metadata": {
        "id": "EShyQrfrvqt-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract questions and answers\n",
        "questions = [item[\"question\"] for item in corpus]\n",
        "answers = [item[\"answer\"] for item in corpus]\n",
        "\n",
        "# Preprocess questions and answers\n",
        "preprocessed_questions = [preprocess_text(question) for question in questions]\n",
        "preprocessed_answers = [preprocess_text(answer) for answer in answers]\n",
        "\n",
        "# Combine preprocessed questions and answers into a single corpus for TF-IDF training\n",
        "combined_corpus = preprocessed_questions + preprocessed_answers\n",
        "\n",
        "# Initialize and fit the TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "vectorizer.fit(combined_corpus)\n",
        "\n",
        "# Save the vectorizer model\n",
        "joblib.dump(vectorizer, \"vectorizer.joblib\")\n",
        "\n",
        "# Transform each question into a TF-IDF vector\n",
        "question_vectors = vectorizer.transform(preprocessed_questions)\n",
        "\n",
        "# Prepare data for saving to vector.json\n",
        "vector_data = []\n",
        "for question, answer, vector in zip(questions, answers, question_vectors):\n",
        "    vector_data.append({\n",
        "        \"question\": question,\n",
        "        \"answer\": answer,\n",
        "        \"vector\": vector.toarray().tolist()[0]  # Convert sparse matrix to dense list\n",
        "    })\n",
        "\n",
        "# Save the vectors to vector.json\n",
        "with open(\"vector.json\", \"w\") as file:\n",
        "    json.dump(vector_data, file, indent=4)\n",
        "\n",
        "print(\"Training complete and data saved to vectorizer.joblib and vector.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhFvSrGMwQ0P",
        "outputId": "547c8c86-7cc3-43b7-ef49-3b9f7687d706"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete and data saved to vectorizer.joblib and vector.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Proses Testing hasil Training Model"
      ],
      "metadata": {
        "id": "4UPU6Im6x3An"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import joblib\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import euclidean_distances"
      ],
      "metadata": {
        "id": "V00xsCknyB1l"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the vectorizer and vector data\n",
        "vectorizer = joblib.load(\"vectorizer.joblib\")\n",
        "\n",
        "with open(\"vector.json\", \"r\") as file:\n",
        "    question_vectors = json.load(file)"
      ],
      "metadata": {
        "id": "XqJlauq5yJRF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set threshold for distance\n",
        "THR = 1  # Adjust this value based on testing and requirement\n",
        "\n",
        "def find_best_match(user_question):\n",
        "    # Transform the user question into a TF-IDF vector\n",
        "    user_vector = vectorizer.transform([user_question]).toarray()\n",
        "\n",
        "    closest_distance = float(\"inf\")\n",
        "    closest_question = None\n",
        "    closest_answer = None\n",
        "\n",
        "    for item in question_vectors:\n",
        "        question_vector = np.array(item[\"vector\"]).reshape(1, -1)\n",
        "        distance = euclidean_distances(user_vector, question_vector)[0][0]\n",
        "\n",
        "        # Check if this question is the closest and below the threshold\n",
        "        if distance < closest_distance and distance <= THR:\n",
        "            closest_distance = distance\n",
        "            closest_question = item[\"question\"]\n",
        "            closest_answer = item.get(\"answer\", \"Maaf, tidak ada jawaban yang tersedia.\")\n",
        "\n",
        "    return closest_question, closest_answer, closest_distance"
      ],
      "metadata": {
        "id": "x3834A3UycPa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Main Q&A loop\n",
        "print(\"Selamat datang di sistem tanya jawab Emerald Mabel. Ketik 'exit' untuk keluar.\")\n",
        "\n",
        "while True:\n",
        "    user_question = input(\"Anda: \")\n",
        "    if user_question.lower() == \"exit\":\n",
        "        print(\"Terima kasih telah menggunakan layanan kami. Sampai jumpa!\")\n",
        "        break\n",
        "\n",
        "    closest_question, closest_answer, closest_distance = find_best_match(user_question)\n",
        "\n",
        "    if closest_question:\n",
        "        print(f\"Pertanyaan terkait: {closest_question}\")\n",
        "        print(f\"Emerald Mabel: {closest_answer}\")\n",
        "    else:\n",
        "        print(\"Maaf, kami tidak menemukan jawaban yang sesuai dengan pertanyaan Anda.\")\\"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNoR0aQkyhSz",
        "outputId": "f6c057dd-ae91-4885-ac0a-609de58e9ae2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selamat datang di sistem tanya jawab Emerald Mabel. Ketik 'exit' untuk keluar.\n",
            "Anda: apa itu emerald\n",
            "Maaf, kami tidak menemukan jawaban yang sesuai dengan pertanyaan Anda.\n",
            "Anda: Apakah Emerald Mabel menyediakan pengiriman\n",
            "Pertanyaan terkait: Apakah Emerald Mabel menyediakan pengiriman untuk semua produk?\n",
            "Emerald Mabel: Ya, kami menyediakan layanan pengiriman untuk semua produk kami. Biaya pengiriman dapat bervariasi tergantung lokasi.\n",
            "Anda: exit\n",
            "Terima kasih telah menggunakan layanan kami. Sampai jumpa!\n"
          ]
        }
      ]
    }
  ]
}